{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eed6a413-abf4-44b3-9a69-b1483eaad5e0",
   "metadata": {},
   "source": [
    "# Practical 1: Unsupervised learning and AI Peer-Programming\n",
    "Our first lecture introduced us to the different types of machine learning, their use cases, and underlying data structures. Given that the course focuses on supervised learning, we use this introductory practice session and shed, at least, some light on *unsupervised learning*.\n",
    "\n",
    "Further, we use this notebook to illustrate the capabilities of Generative AI (GenAI). More specifically, we examine how GenAI (e.g., ChatGPT), can help us develop Python codes. To that end, the notebook provides a set of prompts to generate Python codes. Your task is to try out these prompts using an AI of your choice and experiment with the generated programming codes. \n",
    "\n",
    "We suggest you begin with the prepared prompts. Afterwards, you are most welcome to make adjustments and examine how changes in your prompts change the generated codes; and by extension the effectiveness of the GenAI support. \n",
    "\n",
    "**Disclaimer** Prompts were tested with different versions of ChatGTP and should work reasonably well. That said, there is no guarantee that the provided prompts lead an AI to produce ready-to-use code. As said, one learning goal of this session is to *study how GenAI can help us*. We should not expect it to do all the work.\n",
    "\n",
    "Let's move on with the first prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a112d3d7-842f-46c4-96c0-1055eeda8760",
   "metadata": {},
   "source": [
    "## Prompt 1: Cluster analysis\n",
    "Generate a Python script that demonstrates unsupervised machine learning using cluster analysis. Your script should perform the following tasks:\n",
    "1. Generate a synthetic data set. To facilitate visualization, restrict the data to two features. The synthetic data points should stem from different clusters, to ensure suitability of the data for a clustering demo. \n",
    "2. Visualize the data using a scatter plot. Use different symbols to distinguish data points from different clusters.\n",
    "3. Demonstrate how to run a clustering algorithm on the data\n",
    "4. Visualize the output of the clustering algorithm in a second plot. This plot should depict, the true cluster membership of each data point and to which cluster the data point was assigned by the clustering algorithm. Users shall easily see whether the algorithm assigned data points to the correct cluster.  \n",
    "\n",
    "Make sure the code is ready to be executed. For example, import all necessary libraries. Also make sure to annotate the code using comments for better comprehensibility. Also, the code should allow users to easily adjust the difficulty of the clustering task.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22ff4e9",
   "metadata": {},
   "source": [
    "#### Copy the generated codes into the below code cell and execute it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029746c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from itertools import cycle\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Parameters to adjust clustering difficulty\n",
    "num_samples = 300         # Number of data points\n",
    "num_clusters = 4          # Number of actual clusters in data\n",
    "cluster_std = 1.0         # Standard deviation of clusters (higher = more overlap)\n",
    "\n",
    "# 1. Generate a synthetic dataset with true cluster labels\n",
    "data, true_labels = make_blobs(n_samples=num_samples, \n",
    "                               centers=num_clusters, \n",
    "                               n_features=2,  # 2 features for easy visualization\n",
    "                               cluster_std=cluster_std, \n",
    "                               random_state=42)\n",
    "\n",
    "# Marker generator for different true clusters\n",
    "markers = cycle(['o', 's', 'v', '^', '<', '>', 'p', 'h'])\n",
    "\n",
    "# 2. Visualize the data with true cluster memberships using different markers\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(num_clusters):\n",
    "    plt.scatter(data[true_labels == i, 0], data[true_labels == i, 1], \n",
    "                marker=next(markers), label=f'True Cluster {i+1}', edgecolor='k')\n",
    "plt.title('Generated Data with True Clusters')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 3. Apply K-means clustering algorithm\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "predicted_labels = kmeans.fit_predict(data)\n",
    "\n",
    "# Reset markers for consistency\n",
    "markers = cycle(['o', 's', 'v', '^', '<', '>', 'p', 'h'])\n",
    "\n",
    "# 4. Visualize the clustering results in a second plot\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot with true cluster labels\n",
    "for i in range(num_clusters):\n",
    "    ax[0].scatter(data[true_labels == i, 0], data[true_labels == i, 1], \n",
    "                  marker=next(markers), label=f'True Cluster {i+1}', edgecolor='k')\n",
    "ax[0].set_title('True Clusters')\n",
    "ax[0].set_xlabel('Feature 1')\n",
    "ax[0].set_ylabel('Feature 2')\n",
    "ax[0].legend()\n",
    "\n",
    "# Plot with predicted cluster labels and centroids\n",
    "markers = cycle(['o', 's', 'v', '^', '<', '>', 'p', 'h'])\n",
    "for i in range(num_clusters):\n",
    "    ax[1].scatter(data[predicted_labels == i, 0], data[predicted_labels == i, 1], \n",
    "                  marker=next(markers), label=f'Predicted Cluster {i+1}', edgecolor='k')\n",
    "ax[1].scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], \n",
    "              s=200, c='red', label='Centroids', marker='X')\n",
    "ax[1].set_title('K-Means Clustered Data')\n",
    "ax[1].set_xlabel('Feature 1')\n",
    "ax[1].set_ylabel('Feature 2')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7037b8",
   "metadata": {},
   "source": [
    "#### Code inspection\n",
    "As said, the above prompt should work reasonably well, meaning that, at this point, you should have codes for a clustering demo and the corresponding results in front of you.\n",
    "\n",
    " The above assumed, note how our prompt explicitly asked for a means to control the difficulty of the clustering task. Review the generated codes and find out how you can achieve this. Adjust the codes to increase the clustering task complexity and rerun them to verify everything worked out as expected. Feel free to repeat this exercise multiple time with various levels of task complexity. This should give you a good understanding of when the clustering algorithm works well and when it fails."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a079559",
   "metadata": {},
   "source": [
    "#### Code revision\n",
    "It is safe to assume that the generated codes were not perfect. Did you spot any issue you think warrants improvement? \n",
    "Go back to your AI and try to make it generate better code. You can either revise the prompt or continue the 'discussion' with the AI and ask it to make improvements.  \n",
    "\n",
    "In case you did not spot any issue, you could feed the generated codes back into the AI and task it to suggest improvements. To do that, you could start your prompt like so:\n",
    "\n",
    "*Below is a snippet of Python code aimed at demonstrating unsupervised learning using clustering. Review the code and make suggestions for improvement.*\n",
    "``` Python\n",
    "{Copy the generated codes into the prompt}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f574f900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space to copy improved AI-generated codes to demonstrate clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868eb81a",
   "metadata": {},
   "source": [
    "\n",
    "## Prompt 2: Dimensionality reduction\n",
    "The lecture also introduced another form of unsupervised learning, namely dimensionality reduction. With our second prepared prompt, we try to generate code that demonstrates how to perform dimensionality reduction in Python.\n",
    "\n",
    "**Suggested prompt:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800a26e3",
   "metadata": {},
   "source": [
    "\n",
    "Write a Python script that demonstrates unsupervised learning in the form of dimensionality reduction. Specifically, your script should perform the following tasks:\n",
    "\n",
    "1. Generate a synthetic, high-dimensional data set. The number of features should be a parameter that users can control easily. The data should  comprise a user-defined number of clusters.\n",
    "\n",
    "2. Demonstrate the application of an algorithm for dimensionality reduction. Select a suitable algorithm. Your algorithm should output a two-dimensional projection of the original data to facilitate visualization.\n",
    "\n",
    "3. Visualize the two-dimensional data set by means of a scatter plot. \n",
    "\n",
    "Make sure the generated code is ready to be executed by importing all relevant libraries.  Annotate your code for better readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86d26bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy and execute generated code here:\n",
    "\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Parameters for data generation\n",
    "num_samples = 500      # Number of data points\n",
    "num_features = 10      # Number of features (changeable to control data dimensionality)\n",
    "num_clusters = 4       # Number of clusters\n",
    "\n",
    "# 1. Generate a synthetic high-dimensional dataset\n",
    "data, labels = make_blobs(n_samples=num_samples, \n",
    "                          centers=num_clusters, \n",
    "                          n_features=num_features, \n",
    "                          cluster_std=1.5, \n",
    "                          random_state=42)\n",
    "\n",
    "# 2. Apply PCA for dimensionality reduction to 2 dimensions\n",
    "pca = PCA(n_components=2)\n",
    "data_2d = pca.fit_transform(data)\n",
    "\n",
    "# 3. Visualize the 2D projected data\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(data_2d[:, 0], data_2d[:, 1], c=labels, cmap='viridis', marker='o', edgecolor='k')\n",
    "plt.colorbar(scatter, label='Cluster Labels')\n",
    "plt.title('2D Projection of High-Dimensional Data via PCA')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3557178",
   "metadata": {},
   "source": [
    "## Programming task:\n",
    "If the prepared prompt worked as intended, your synthetic high-dimensional data set should comprise clusters. The 2D projection of the data should also show these clusters. Let's see whether we can also find these clusters in the original, high-dimensional data using a clustering algorithm.\n",
    "\n",
    "Specifically, drawing on the code generated in response to our first prompt, your task is to write a Python script that clusters your high-dimensional data set. \n",
    "\n",
    "We suggest you try to solve this task without the help of Gen-AI. \n",
    "\n",
    "*Additional task for the experts:* try to find a way to verify that the algorithm found the correct number of clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc8daf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply k-means algorithm:\n",
    "num_clusters = 3  # we must determine the number of clusters a priori\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "predicted_labels = kmeans.fit_predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7803f08",
   "metadata": {},
   "source": [
    "While the above code is enough to solve the task, examining the resulting clustering is suitable is more challenging. \n",
    "\n",
    "Since we use synthetic data, an intuitive approach is to compare the true cluster membership (i.e., the variable `labels` that the `make_blobs` function returns) to the output of the `fit_predict` method. Unfortunately, this does not work because of the **arbitrary cluster indexing** in both `make_blobs` and K-means. While `make_blobs` assigns indices to clusters when generating synthetic data, K-means does not know these labels and assigns its own arbitrary indices based on how it organizes clusters during training.\n",
    "\n",
    "This discrepancy means that even if the clustering is perfectly accurate in terms of data point grouping, the indices of clusters in `make_blobs` and K-means may not align (e.g., what `make_blobs` labels as cluster `0`, K-means might label as cluster `2`). \n",
    "\n",
    "To align indices for accurate comparison, we can use the **Hungarian method** to optimally map K-means cluster indices to the true labels, allowing us to objectively assess clustering performance without being affected by differing label assignments.\n",
    "\n",
    "Here is an example how to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12472593",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.optimize import linear_sum_assignment as hungarian\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_matrix = confusion_matrix(labels, predicted_labels)\n",
    "\n",
    "# Use the Hungarian algorithm to find the best label mapping\n",
    "row_ind, col_ind = hungarian(-conf_matrix)  # Negate because linear_sum_assignment minimizes cost\n",
    "\n",
    "# Map predicted labels to match true labels\n",
    "mapped_labels = np.zeros_like(predicted_labels)\n",
    "for i, j in zip(row_ind, col_ind):\n",
    "    mapped_labels[predicted_labels == j] = i\n",
    "\n",
    "# Check quality of cluster assignment \n",
    "# by computing the share of correct assignments\n",
    "\n",
    "accuracy = sum(mapped_labels==labels)/len(labels)\n",
    "print(f\"kMeans achieves {accuracy*100} percent accuracy.\")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

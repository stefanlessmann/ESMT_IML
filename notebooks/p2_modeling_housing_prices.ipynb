{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf0157e3-1b74-4592-8494-86ac3be129e0",
   "metadata": {
    "id": "ce46c39d-cfa8-4bca-82b2-c6364fd44819"
   },
   "source": [
    "# Practical 2: Forecasting Housing Prices\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wIgF2_GabxOZ",
   "metadata": {
    "executionInfo": {
     "elapsed": 2466,
     "status": "ok",
     "timestamp": 1695536714957,
     "user": {
      "displayName": "Ben Joshua Fliegener",
      "userId": "06969016385245233563"
     },
     "user_tz": -120
    },
    "id": "wIgF2_GabxOZ"
   },
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23538915-b8b4-465b-9d6e-e6539f238144",
   "metadata": {
    "id": "ce46c39d-cfa8-4bca-82b2-c6364fd44819"
   },
   "source": [
    "## The California Housing data set\n",
    "\n",
    "The \"California Housing\" data set is a widely used data set to demonstrate forecasting methods. As the name suggests, the data set concerns the valuation of real estate. It comprises socio-demographic information concerning the area of a property and a dependent (aka target) variable, which gives the median house value for California districts. This data was derived from the 1990 U.S. census. \n",
    "\n",
    "Being so popular, the data set is readily available in standard Python libraries. Execute the following code to load the data set from `sklearn.datasets` and familiarize yourself with the data description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df4cc9d-5bb8-47cc-948a-4ab6413a6189",
   "metadata": {
    "executionInfo": {
     "elapsed": 1738,
     "status": "ok",
     "timestamp": 1695536716691,
     "user": {
      "displayName": "Ben Joshua Fliegener",
      "userId": "06969016385245233563"
     },
     "user_tz": -120
    },
    "id": "1df4cc9d-5bb8-47cc-948a-4ab6413a6189"
   },
   "outputs": [],
   "source": [
    "# Downloading the data set\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "california_housing = fetch_california_housing(as_frame=True)  # get the data as a Pandas dataframe\n",
    "\n",
    "print(california_housing.DESCR)  # the data even comes with a nice description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0489dd6-54fd-4ac2-ae35-6385427131dd",
   "metadata": {},
   "source": [
    "The `sklearn` library provides the data in a specific format. Feature values and the target variable are already separated. The be consistent with our standard notation, we extract the feature values and target and store it, as usual, in variables $X$ and $y$, respectively. Of course, this is a good opportunity to also take a quick look into the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cf24cd-e9b2-4264-8b99-7f7c1096f31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = california_housing.data\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fdbb36-d876-473c-9f8d-103e3d2ddad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = california_housing.target\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d88f2f1-c54e-4a69-a159-96a64b3daec6",
   "metadata": {},
   "source": [
    "### Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ada977f-144d-4163-87f6-b47238761c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.describe()  # compute descriptive statistics that summarize the target's distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839a3bc8-b53d-43bb-a5b7-0340ac3a4bba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.describe() # do the same for all features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a41e3b-0ea4-4697-a921-84b1651ec36d",
   "metadata": {},
   "source": [
    "### Explanatory data analysis (EDA)\n",
    "To better understand the data, we consider a few standard EDA operations. They comprise the analysis of histograms and/or box-plots of the target and the features. Also, we consider the (linear) correlation between features and the target to obtain some initial evidence as to which features might be important. \n",
    "\n",
    "While we only create the plots in the following, never forget that each plot - and more generally every result - deserves a careful analysis and discussion. Therefore, make sure to examine each plot and note down your key observations.\n",
    "\n",
    "Without any strong reason, we use the `seaborn` library for plotting in this notebook. Many data scientists prefer `seaborn` over `Matplotlib`. Hence, we illustrate it here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e420d55-5e3a-474f-b53d-f87c72afcfd7",
   "metadata": {},
   "source": [
    "#### Target Variable: Medium House Value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197b8bb7",
   "metadata": {},
   "source": [
    "##### Analyzing the distribution of the target by means of a histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WXjFWs3zF31A",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 333,
     "status": "ok",
     "timestamp": 1695536838762,
     "user": {
      "displayName": "Ben Joshua Fliegener",
      "userId": "06969016385245233563"
     },
     "user_tz": -120
    },
    "id": "WXjFWs3zF31A",
    "outputId": "c5473e54-8a6c-4908-f220-f0c7034d04e9"
   },
   "outputs": [],
   "source": [
    "# Histogram of target\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(y, bins=30, kde=False, edgecolor='k')\n",
    "plt.xlabel(y.name)\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(f'Distribution of {y.name}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa9d825",
   "metadata": {},
   "source": [
    "##### Analyzing the distribution of the target by means of a boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1e5a28-cf93-4181-b516-779616999f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=y, color='skyblue');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618de746-2510-4f06-a083-865162740f15",
   "metadata": {},
   "source": [
    "#### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xdXLDm-OF4Sn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 771
    },
    "executionInfo": {
     "elapsed": 1210,
     "status": "ok",
     "timestamp": 1695536812007,
     "user": {
      "displayName": "Ben Joshua Fliegener",
      "userId": "06969016385245233563"
     },
     "user_tz": -120
    },
    "id": "xdXLDm-OF4Sn",
    "outputId": "745d4107-6eed-431a-c3fa-1ed56aea2b05"
   },
   "outputs": [],
   "source": [
    "#3x3 matrix of box-plots for all the features\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))  # Create a 3x3 grid of subplots\n",
    "axes = axes.flatten() # Flatten the axes for easier iteration\n",
    "\n",
    "# Loop through each feature and create a box plot\n",
    "for i, feature in enumerate(X.columns):\n",
    "    sns.boxplot(x=X[feature], ax=axes[i], color='skyblue')\n",
    "    axes[i].set_title(f'Box Plot of {feature}')\n",
    "    axes[i].set_xlabel(feature)\n",
    "\n",
    "# Remove empty subplots\n",
    "for i in range(len(X.columns), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout()  # Adjust layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4d3ad5-13fa-45a2-8226-79c3aeee595e",
   "metadata": {},
   "source": [
    "#### Correlation analysis\n",
    "Having obtained an idea about the *univariate* distributions, we also take a look at the correlation structure in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e09df1-2978-4e25-a0d9-4a06037729fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "executionInfo": {
     "elapsed": 288,
     "status": "ok",
     "timestamp": 1695536838139,
     "user": {
      "displayName": "Ben Joshua Fliegener",
      "userId": "06969016385245233563"
     },
     "user_tz": -120
    },
    "id": "e_t4YznoF4AF",
    "outputId": "9e7d58d7-47c6-4418-db79-24b74d2f2afb"
   },
   "outputs": [],
   "source": [
    "# Correlation among the features\n",
    "corr_matrix = X.corr()  \n",
    "sns.heatmap(corr_matrix, cmap='vlag', annot=True)\n",
    "plt.title('Feature correlation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f7cc71-9e52-4f7f-905f-e769468987c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between individual features and the target\n",
    "rho = X.corrwith(y)\n",
    "print(rho)\n",
    "\n",
    "sns.barplot(x=rho, y=X.columns.tolist(), orient='h')\n",
    "plt.title('Feature to target correlation')\n",
    "plt.xlabel('Correlation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc47300a-b43f-4482-a20a-034d18f92a0c",
   "metadata": {
    "id": "64fizQ6g6rQg"
   },
   "source": [
    "## Linear Regression\n",
    "Having completed our initial data screening and explorative analysis, we proceed by estimating a linear regression model to deepen our understanding of how the features and the target are related to another.\n",
    "\n",
    "To that end, we consider the library `statsmodels`, a popular and powerful library for statistical modeling, which includes ordinary least squares (OLS) estimator. We provide all codes for the model estimation below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e353f01-f945-4734-bbf5-22ac905d10f4",
   "metadata": {
    "executionInfo": {
     "elapsed": 664,
     "status": "ok",
     "timestamp": 1695536839415,
     "user": {
      "displayName": "Ben Joshua Fliegener",
      "userId": "06969016385245233563"
     },
     "user_tz": -120
    },
    "id": "edVKGWXfgWtf"
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm \n",
    "\n",
    "# OLS model estimation\n",
    "model = sm.OLS(y,\n",
    "               sm.add_constant(X)  # include an intercept\n",
    "              ) \n",
    "\n",
    "results = model.fit()  # fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072a9c41-e584-455f-8081-4f4d86a55631",
   "metadata": {
    "id": "64fizQ6g6rQg"
   },
   "source": [
    "The library provides a neat function, `.summary()` to obtain a concise overview of the results of regression analysis. It includes key information like R-squared, estimated coefficients, standard errors, and p-values. This summary is crucial for evaluating model adequacy and feature significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9d635c-b74b-4dde-9c41-1ebe06c9c392",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1695536839415,
     "user": {
      "displayName": "Ben Joshua Fliegener",
      "userId": "06969016385245233563"
     },
     "user_tz": -120
    },
    "id": "7GQ935p6WhxW",
    "outputId": "d0a8fb32-c2a8-41b6-8141-fc82fb6402ca"
   },
   "outputs": [],
   "source": [
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dbf141-f21e-4c9e-9c94-51b07f1f634e",
   "metadata": {
    "id": "ce46c39d-cfa8-4bca-82b2-c6364fd44819"
   },
   "source": [
    "# Exercises\n",
    "Based on the above analysis, draw on your data science expertise to answer the following questions: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4373d5-09a1-430d-a6c2-41ea75601c3b",
   "metadata": {
    "id": "ce46c39d-cfa8-4bca-82b2-c6364fd44819"
   },
   "source": [
    "## 1. What are the two most and the two least important features?\n",
    "Briefly note what statistics/results you have considered to make your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2714140-c525-4909-abca-c0b03412ad9d",
   "metadata": {},
   "source": [
    "**Enter your answer in this markup cell:**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c03ef4-6116-4ae0-8118-0f3f1d0e9087",
   "metadata": {
    "id": "ce46c39d-cfa8-4bca-82b2-c6364fd44819"
   },
   "source": [
    "## 2. Scatter Plots\n",
    "Create, for each of the selected features, a scatter plot of the selected feature against the target. Display these plots in a 2x2 grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab58cdf-a21b-4601-b60f-2fc2938da206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for plotting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2445b153-5b13-4903-9c38-a97aa6f27a09",
   "metadata": {
    "id": "ce46c39d-cfa8-4bca-82b2-c6364fd44819"
   },
   "source": [
    "## 3. Model Reestimation\n",
    "Remove the two least important features from the data and reestimate the model. Briefly discuss whether this step has improved the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908535cb-275a-49a5-9e11-772144f60b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to reestimate the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa95dc0-f8f9-4084-95cb-39cb60e4dbf5",
   "metadata": {},
   "source": [
    "**Did the model improve? Briefly discuss:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b9c155-83a8-4a5c-a341-7433b354734a",
   "metadata": {},
   "source": [
    "## 4. Switching the Library\n",
    "We have used `statsmodels` up to this point. However, the go-to library when it comes to machine learning is a different library called [scikit-learn](https://scikit-learn.org/stable/), typically abbreviated as `sklearn`.\n",
    "\n",
    "Import that library. Then, using once more the data set with all features included, create another linear regression model using the class `linear_model.LinearRegression()`. Compare the coefficients between this model and the one we estimated above using `statsmodels.api.OLS`. They should be pretty much identical. Please verify that they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d5f53e-7be4-47ce-b9f0-719f3f17882e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to estimate linear regression using sklearn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631a235c-24c9-4939-b3db-bfebef3a00df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to compare regression coefficients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22ba9cc-b879-4094-923f-22e1f8388af8",
   "metadata": {},
   "source": [
    "## 5. Prediction \n",
    "We next use our regression model for prediction. Feeding it with data on feature values, the estimated regression coefficients facilitate forecasting real-estate prices. \n",
    "\n",
    "For start, compute forecasts for the training data, that is, the data from which you estimated the regression coefficients. Store your forecasts in a variable, `y_hat`, and assess them in terms of mean squared error (MSE), defined as: <br><br>\n",
    "$ MSE = \\frac{1}{n}\\sum_{i=1}^{n} \\left( Y_i - \\hat{Y}_i \\right)^2 $,\n",
    "<br><br>\n",
    "with:\n",
    "- $n$ = number of data points\n",
    "- $Y$ = true values of the target variable\n",
    "- $\\hat{Y}$ = forecasts of the regression model\n",
    "\n",
    "> Hint: if unsure how to implement the MSE yourself, you can be sure that ready-made functions are available to do it for you ;)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dc3e57-bbe7-4cd9-be90-12c014622ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to assess regression model forecasts using MSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592b0983-acdc-4231-908f-9c1ec2818b7e",
   "metadata": {},
   "source": [
    "## Closing questions\n",
    "- We assessed the model in terms of MSE. Why is the root of the MSE often preferred in practice?\n",
    "- Beyond (R)MSE, considering all results observed in the notebook, what is your overall opinion of the regression model?\n",
    "- No model is perfect. What could we try to improve the value of the regression model for forecasting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d260551-e9c2-4fca-8c80-e987e3eaf032",
   "metadata": {},
   "source": [
    "**Space to take notes on the above points**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34edc1f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c62e5dc",
   "metadata": {},
   "source": [
    "# EXTRA Exercise (Challenging!):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae8923a",
   "metadata": {},
   "source": [
    "## Backward Elimination \n",
    "We examined the effect of discarding features in a previous exercise. This task takes a more comprehensive approach toward feature selection.\n",
    "\n",
    "Relying on the following pseudo code, implement a *backward elimination* procedure, in which you repetitively discard the least important feature from the regression model.\n",
    "\n",
    "```\n",
    "    Use all features as the current set of features  \n",
    "    Do \n",
    "        Estimate a regression model using current set of features\n",
    "        Store model performance in terms of a suitable statistic\n",
    "        Identify the least important feature\n",
    "        Discard that feature from current set of features\n",
    "    Repeat until all features but one have been deleted\n",
    "   \n",
    "```\n",
    "Depict your results graphically by plotting the number of features in the regression model against model performance using the same statistic as in your backward elimination algorithm.\n",
    ">Hint: given you have to run the code inside the above *Do ... Repeat* block multiple times, consider implementing this part as a custom function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34987c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for your backward elimination algorithm:\n",
    "#-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4433433d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for visualizing the results of backward elimination\n",
    "# ----------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "bads",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

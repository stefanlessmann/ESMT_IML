{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84bf70f4-915d-4738-b78c-700b27b06f38",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/stefanlessmann/ESMT_IML/blob/main/notebooks/p4_model_evaluation.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32daf08-0c21-4ea8-8c23-b76b4be5b806",
   "metadata": {},
   "source": [
    "# Practical 4: Prediction Model Evaluation\n",
    "<hr>\n",
    "We have learned about linear and logistic regression. These methods facilitate supervised learning and enable us to approach prediction problems with a numerical (e.g., price) or categorical (e.g., repayment behavior=good or bad) target variable. \n",
    "\n",
    "In this session, we focus on practices to assess the accuracy of predictive models based on linear or logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fc25b5-773f-47f3-a832-54fd0338dac4",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "We will use the two data sets introduced in previous sessions, the *California Housing* data set from [practical #2](https://github.com/stefanlessmann/ESMT_IML/blob/main/notebooks/p2_modeling_housing_prices.ipynb) and the *HMEQ* data set from [practical #3](https://github.com/stefanlessmann/ESMT_IML/blob/main/notebooks/p3_classification.ipynb), which represent, respectively, a regression problem associated with modeling median house prices at the district level and a classification problem associated with predicting the repayment behavior of credit applicants (aka credit risk modeling). Below we reproduce codes from earlier sessions to import standard libraries, load the data sets, and perform some rudimentary data preprocessing where needed. Just execute those codes and we are ready to go.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "828b49a3-f1ff-41fa-86d2-473b80a82bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded California Housing data set with dimension (rows x columns) 20640 x 8\n",
      "Loaded HMEQ credit risk data set with dimension (rows x columns) 3515 x 18\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "#--------------------------------------------------------\n",
    "# Loading the California Housing data set\n",
    "#--------------------------------------------------------\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "calh = fetch_california_housing(as_frame=True)  # get the data as a Pandas dataframe\n",
    "# separate the data into feature matrix X and target variable y\n",
    "X_calh = calh.data\n",
    "y_calh = calh.target\n",
    "print('Loaded California Housing data set with dimension (rows x columns) {} x {}'.format(*X_calh.shape))\n",
    "#--------------------------------------------------------\n",
    "# Training (aka fitting) a linear regression model\n",
    "#--------------------------------------------------------\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression().fit(X_calh, y_calh)\n",
    "#--------------------------------------------------------\n",
    "# Loading the HMEQ credit risk data set\n",
    "#--------------------------------------------------------\n",
    "data_url = 'https://raw.githubusercontent.com/stefanlessmann/ESMT_IML/master/data/hmeq.csv'\n",
    "hmeq = pd.read_csv(data_url)  # standard pandas function to load tabular data in CSV format\n",
    "\n",
    "# Convert a category with k different values into k-1 binary variables. \n",
    "X_hmeq = pd.get_dummies(hmeq, dummy_na=True, drop_first=True)\n",
    "X_hmeq = X_hmeq.dropna().reset_index(drop=True)  # drop all cases with one or more missing value\n",
    "\n",
    "# Separate the data into a matrix of feature values and a target variable\n",
    "y_hmeq = X_hmeq.pop('BAD')\n",
    "print('Loaded HMEQ credit risk data set with dimension (rows x columns) {} x {}'.format(*X_hmeq.shape))\n",
    "#--------------------------------------------------------\n",
    "# Training logistic regression-based classification model\n",
    "#--------------------------------------------------------\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression().fit(X_hmeq, y_hmeq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fe3e44-caaf-498d-855d-8a61711d0eb9",
   "metadata": {},
   "source": [
    "## Foundations of ML Model Evaluation\n",
    "Today we want to focus on prediction model evaluation. That said, an ML model has many facets, that deserve to be evaluated. Examples include:\n",
    "- Interpretability\n",
    "- Robustness\n",
    "- Scalability\n",
    "- and many more\n",
    "\n",
    "Our focus, in this session, is **predictive accuracy**. We will learn practices to rigorously assess the forecasts coming from a predictive model. Speaking about predictive accuracy...\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/stefanlessmann/ESMT_IML/main/resources/model_evaluation.png\" width=\"600\" height=\"600\" alt=\"Prediction Model Evaluation\">\n",
    "\n",
    "So, as discussed in the lecture, the evaluation of prediction performance is all about comparing model-based forecasts to actual outcomes. There are **two key ingredients** to make this comparison work. First, we must define what we mean by *performance*. For this, we need suitable accuracy or error measures. Second, we must organize our data suitably to simulate a real-world application of a model. Before diving into each of these stages, let's revisit how we obtain predictions in the first place. This is where the `predict()` function of `sklearn` comes in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c31a5ca-6136-4f4d-9396-07412a4b595a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Median house value (Y)</th>\n",
       "      <th>Model prediction (Yhat)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.526</td>\n",
       "      <td>4.131650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.585</td>\n",
       "      <td>3.976606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.521</td>\n",
       "      <td>3.676571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.413</td>\n",
       "      <td>3.241598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.422</td>\n",
       "      <td>2.413587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Median house value (Y)  Model prediction (Yhat)\n",
       "0                   4.526                 4.131650\n",
       "1                   3.585                 3.976606\n",
       "2                   3.521                 3.676571\n",
       "3                   3.413                 3.241598\n",
       "4                   3.422                 2.413587"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demo of how to obtain predictions from our regression model for the California Housing data\n",
    "yhat_calh = lin_reg.predict(X_calh)  # forecasts of the median house value (i.e. the target) for the TRAINING data\n",
    "\n",
    "# Visualize actual realizations of the target and the corresponding predictions by \n",
    "# putting them together in a data frame. \n",
    "df_Y_cf_Yhat = pd.DataFrame({'Median house value (Y)' : y_calh, 'Model prediction (Yhat)': yhat_calh})  \n",
    "df_Y_cf_Yhat.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f0ee0db-e3f4-43bf-954a-daea5dafa610",
   "metadata": {},
   "source": [
    "Equipped with this information, actual outcomes of the target variable and corresponding model predictions, we are ready to compute performance statistics. For example, the lecture introduced you to statistics like the *mean square error (MSE)* or *root mean square error (RMSE)*. Just to remind you, their mathematical definition was: \n",
    "\n",
    "$$\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^n (Y_i - \\hat{Y}_i)^2 ;\\qquad   \\text{RMSE} = \\sqrt{\\text{MSE}}  $$\n",
    "\n",
    "$$\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^n |Y_i - \\hat{Y}_i| $$\n",
    "\n",
    "$$\\text{MAPE} = \\frac{1}{n} \\sum_{i=1}^n \\left|\\frac{Y_i - \\hat{Y}_i}{Y_i}\\right|  $$\r\n",
    "\n",
    "We could easily compute these error measures using `numpy`. Consider, for example, the MSE and RMSE. Their calculation would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db44f720-2cb0-41de-b781-0499a632fe7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of the regression model is 0.524\n",
      "RMSE of the regression model is 0.724\n"
     ]
    }
   ],
   "source": [
    "mse = 1/len(yhat_calh) * np.sum((y_calh - yhat_calh)**2)\n",
    "rmse = np.sqrt(mse)\n",
    "print('MSE of the regression model is {:.3f}'.format(mse))\n",
    "print('RMSE of the regression model is {:.3f}'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67260675-bd4f-49cc-ad70-44aa56202cdf",
   "metadata": {},
   "source": [
    "Alternatively, the `sklearn` library provides ready-to-use functions to calculate standard error measures for regression models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcf17d80-efc8-4dca-bf52-807a42e3d458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of the regression model is 0.524\n",
      "RMSE of the regression model is 0.724\n",
      "MAE of the regression model is 0.531\n",
      "MAPE of the regression model is 0.317\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "mse  = mean_squared_error(y_calh, yhat_calh)\n",
    "mae  = mean_absolute_error(y_calh, yhat_calh)\n",
    "mape = mean_absolute_percentage_error(y_calh, yhat_calh)\n",
    "print('MSE of the regression model is {:.3f}'.format(mse))\n",
    "print('RMSE of the regression model is {:.3f}'.format(np.sqrt(mse)))\n",
    "print('MAE of the regression model is {:.3f}'.format(mae))\n",
    "print('MAPE of the regression model is {:.3f}'.format(mape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9d3e1e-fb2b-4859-ace4-ce64ee140dee",
   "metadata": {},
   "source": [
    "#### Exercise 1: \n",
    "With the help of the above demo for the linear regression model, your task is to produce predictions for the logistic regression model. Recall from [practical #3](https://github.com/stefanlessmann/ESMT_IML/blob/main/notebooks/p3_classification.ipynb) that logistic regression can give you two types of outputs, discrete classifications of whether an applicant is a good risk and probability predictions, capturing the model-estimated probability that an applicant is a good risk. Make sure you fully understand how these are different. \n",
    "\n",
    "Your task is to compute both types of predictions for every credit application in the HMEQ data set. Afterward, visualize these predictions next to the true repayment status (i.e., target variable) by putting everything into a pandas data frame, as exemplified above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e02d6f-90ea-4ef3-9a05-b6de54576561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for exercise 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ab028c-11c8-491b-93ad-73264f4e21db",
   "metadata": {},
   "source": [
    "## Data Organization\n",
    "At least for the case of regression, we have seen some examples of suitable - or at least common - measures of forecast accuracy. Before examining the evaluation of our second model, the logistic regression-based credit risk classification model, let's look at the other key ingredient to forecast accuracy evaluation, data organization. \n",
    "\n",
    "Above, when producing predictions and comparing these of observed outcomes, we used all available data. Technically speaking, we did that when executing codes like:\n",
    "```\n",
    "lin_reg.predict(X_calh)\n",
    "\n",
    "```\n",
    "Here, we call the `predict()` function and use all our data, which we store in the variable `X_calh`, as an argument to that function. When training our regression model, we called the corresponding Python function in a similar way, namely:\n",
    "```\n",
    "lin_reg = LinearRegression().fit(X_calh, y_calh)\n",
    "```\n",
    "You can find both statements above in the notebook if unsure. The point is that we use **the same data**, `X_calh` in this case, for model training and when assessing the model. This is bad practice. The lecture has discussed why this is bad practice and future lecture sessions will further elaborate on this crucial point. For now, just accept it is bad practice. We already learned about a better way to organize the data using the **holdout method**. \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/stefanlessmann/ESMT_IML/main/resources/holdout_method.png\" width=\"600\" height=\"600\" alt=\"Holdout Method\">\n",
    "\n",
    "To implement the holdout method in Python we typically use the `train_test_split()` function, which is available in the module `sklearn.model_selection`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2e3158-b82d-4a3f-bd34-12a8cf99ebe9",
   "metadata": {},
   "source": [
    "#### Exercise 2: \n",
    "\n",
    "To familiarize yourself with the holdout method, write some code to perform the following tasks:\n",
    "- Import the `train_test_split()` function and have a look at its documentation\n",
    "- Use this insight to write code that calls the function and splits the California Housing data set, that is your variable `X_calh`, randomly into a **training set** and a **test set**. Your test set should comprise 30% of the total data.\n",
    "- Fit a linear regression model to the **training set**\n",
    "- Assess your regression model by computing the MAE on the **test set**\n",
    "- Also compute the MAE for the training set. Which error is larger?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1824c52-be12-4cfb-8507-8c6c4c565417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for exercise 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b98314-bab2-4d99-906e-6c5ba1b7333c",
   "metadata": {},
   "source": [
    "#### Extra challenge (feel free to skip)\n",
    "You just compared the *test set performance* of the regression model to its *training set performance*. In theory, the error on the test set should be larger but it is well possible that you did not observe this behavior in the previous comparison. It is also possible that your previous comparison found both errors to be roughly the same. Well, so far your comparison has considered **one** random partitioning of the whole data into training and test set. To obtain a more reliable assessment of the training versus test error of the model, it would be useful to repeat the partitioning multiple times. Provided you already feel comfortable with coding, try to do this. More specifically, write code that implements the following logic:\n",
    "```\n",
    "SET parameter r, the number of repetitions to some value > 100\n",
    "\n",
    "REPEAT r times\n",
    "    SPLIT California Housing data set randomly into training (80%) and test set (20%)\n",
    "    FIT linear regression model on the training set\n",
    "    PREDICT test set and compute MAE\n",
    "    PREDICT training set and compute MAE\n",
    "    STORE the MAE on training and on test set\n",
    "\n",
    "PLOT the distribution of the training set MAE and that of the test set MAE over the r repetitions\n",
    "```\n",
    "For the visualization part, you can use any plot you deem fit. Remember that previous practicals have illustrated several standard forms to visualize distributions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fcd946-3012-4792-b525-10157c036537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for the extra challenge - PLEASE SKIP IF YOU THINK THIS WOULD COST YOU A LOT OF TIME \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf2139c-69dd-4b2d-a495-d337637dbd62",
   "metadata": {},
   "source": [
    "### Cross-validation\n",
    "Beyond splitting a data set into training and test set (aka the holdout method), we also introduced cross-validation, the process of partitioning a data set into *k* equally sized folds and repeatedly training a model on the combined data of k-1 folds and evaluating it on the left-out fold *k* times, such that each fold was used exactly once as the holdout or, synonymously , the *validation* fold. Relatively speaking, cross-validation is more reliable but also more costly than the simpler holdout method. It's costly because you have to train *k* models in total, which may cost a lot of time (e.g., when working with large data sets and/or complex ML algorithms). For the very same reason, cross-validation is also more reliable. You do not evaluate using one randomly sampled test set but carry out the evaluation *k* times.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/stefanlessmann/ESMT_IML/main/resources/cross_validation.png\" width=\"800\" height=\"600\" alt=\"Cross Validation\">\n",
    "\n",
    "\n",
    "The `sklearn` library offers you several ways to perform cross-validation. \n",
    "\n",
    "- `cross_val_score()` is a quick and easy way, but does not offer much flexibility. It only returns a single metric, limiting its usefulness if you want to evaluate your model on multiple metrics.\n",
    "- `cross_validate()` allows you to specify multiple evaluation metrics and provides more information about the training and testing procedure.\n",
    "- `KFold()` gives you full control over the cross-validation process and is the most flexible implementation. However, it requires writing more code compared to the other two methods.\n",
    "\n",
    "Each method has its own strengths and weaknesses, and the best choice depends on your specific requirements. Below, we demonstrate the `FKold()` option to demonstrate the most flexible but also most demanding option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b377c99-c1cd-46ba-b7ca-422cb0cbbe14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The raw results per error measure are a list:\n",
      "[0.5351667968101456, 0.5291050430667511, 0.678514774845209, 0.47485744963024495, 0.6519784224910431, 0.5009218650229931, 0.39629860827907276, 0.6400626798803464, 0.6028617579309162, 0.43544699530961234]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate, KFold\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Preliminaries\n",
    "#--------------------------------------------------------------------------------\n",
    "k = 10  # number of folds\n",
    "kf = KFold(n_splits=k)  # initialize cross-validation process\n",
    "\n",
    "# Say we want to assess our regression model in terms of multiple error\n",
    "# measures, just as we did before. Here we create a list of all the\n",
    "# error measures that interest us. \n",
    "error_measures = [mean_absolute_error,               # Note that the entries we put in this list   \n",
    "                  mean_squared_error,                # are actually the functions used before.\n",
    "                  mean_absolute_percentage_error]    # So we construct a list of Python functions\n",
    "err_shorthand = ['MAE', 'MSE', 'MAPE']\n",
    "\n",
    "# We will assess our regression model using each of the error.\n",
    "# We will also measure performance on the test and training set,\n",
    "# so we can compare, as before. To do all this, we need a place\n",
    "# in which we can store the results, that is:\n",
    "# k folds * 3 error measures * 2 sets (training and test).\n",
    "# We use dictionaries for this purpose and initialize one dictionary\n",
    "# for the test set results and another for the training set results. \n",
    "# In these dictionaries we use the name of a error measures as key, and \n",
    "# create an empty list to store the cross-validation results\n",
    "train_errors = {measure: [] for measure in err_shorthand}\n",
    "test_errors = {measure: [] for measure in err_shorthand}\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Iterating over the k folds\n",
    "#--------------------------------------------------------------------------------\n",
    "for train_index, test_index in kf.split(X_calh):  # so KFold gives as two arrays with the indices of the training and validation data of the current iteration\n",
    "    X_train, X_test = X_calh.iloc[train_index], X_calh.iloc[test_index]  # we can use these arrays to index our original data set: here we construct the feature matrices\n",
    "    y_train, y_test = y_calh[train_index], y_calh[test_index]  # and here we construct the arrays with the true targets\n",
    "\n",
    "    # Fitting linear regression model on the training set of THIS ITERATION\n",
    "    model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "    # Compute predictions on the test (and training) set of THIS ITERATION\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Compute model performance for every error measure we are interested in\n",
    "    for i, measure in enumerate(error_measures):\n",
    "        # Recall we created two dictionaries to store the results. First, we\n",
    "        # take the training set results dictionary. We can use the current\n",
    "        # error measure as key to index the dictionary. Doing so returns the \n",
    "        # value that the dictionary associates with this key. Given how we \n",
    "        # created the dictionary, this value is a list. Hence, we can use \n",
    "        # function .append() to add an element to the list. What value to append?\n",
    "        # The value of the error measure, which we calculate inside the below\n",
    "        # call of the append() function. \n",
    "        train_errors[err_shorthand[i]].append(measure(y_train, y_train_pred))\n",
    "        test_errors[err_shorthand[i]].append(measure(y_test, y_test_pred))\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Aggregating the results\n",
    "#--------------------------------------------------------------------------------\n",
    "# The main work is done. We are ready to report and/or visualize our results\n",
    "\n",
    "# For start, let's showcase the raw results for illustration \n",
    "print('The raw results per error measure are a list:')\n",
    "print(test_errors['MAE'])  # same approach for any other error measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83a60d4f-b3ba-422a-976a-060089cf4c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating results in terms of MAE\n",
      "-------------------------------------------\n",
      "\tMEAN TEST set MAE of the regression model is 0.545\n",
      "\tMEAN TRAINING set MAE of the regression model is 0.531\n",
      "\n",
      "Evaluating results in terms of MSE\n",
      "-------------------------------------------\n",
      "\tMEAN TEST set MSE of the regression model is 0.551\n",
      "\tMEAN TRAINING set MSE of the regression model is 0.523\n",
      "\n",
      "Evaluating results in terms of MAPE\n",
      "-------------------------------------------\n",
      "\tMEAN TEST set MAPE of the regression model is 0.325\n",
      "\tMEAN TRAINING set MAPE of the regression model is 0.317\n"
     ]
    }
   ],
   "source": [
    "# Given our results have the form of lists, we could also report averages\n",
    "for i, measure in enumerate(error_measures):\n",
    "    e = err_shorthand[i]  # shorthand form simplify the code\n",
    "    print('\\nEvaluating results in terms of {}'.format(e))\n",
    "    print('-------------------------------------------')\n",
    "    print('\\tMEAN TEST set {} of the regression model is {:.3f}'.format(e, np.mean(test_errors[e])))\n",
    "    print('\\tMEAN TRAINING set {} of the regression model is {:.3f}'.format(e, np.mean(train_errors[e])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75a422bb-30e9-4939-8c57-54d3cb6551dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# And finally, we could create some suitable visualizations that depict how the error varies across folds\n",
    "# For example, we can produce 3 box plots, one for each error measure, and compare test to training error\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))  # Create a figure instance and specify the figure size\n",
    "\n",
    "for i, measure in enumerate(error_measures):\n",
    "    e = err_shorthand[i]  # shorthand form simplify the code\n",
    "    \n",
    "    # Create boxplot on each subplot\n",
    "    axs[i].boxplot([train_errors[e], test_errors[e]], labels=['Train', 'Test'])\n",
    "    axs[i].set_title(e)\n",
    "    \n",
    "axs[0].set_ylabel('Error')  # Just one y-axis label for the leftmost plot\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c41582-ecb7-40f6-b1c9-325c5fc21041",
   "metadata": {},
   "source": [
    "The coding demo was quite comprehensive. It is clearly time to give you a chance to try out your own coding skills. Prior to that, let's quickly note at least a few key findings from our analysis. \n",
    "\n",
    "First, the test error varies a lot more than does the training error. This is less surprising when you remember how cross-validation works. The test set of each iteration contains roughly $\\frac{1}{k}$ of the data while the training set is much bigger, containing all $\\frac{k-1}{k}$ remaining data.\n",
    "\n",
    "Second, in this case, the median of the training and test set error distributions is roughly identical. This finding may look counterintuitive because we motivated cross-validation by saying that the performance on the training set is not a reliable estimate. While this statement is true, the results we observe are still plausible because we used linear regression. It is a characteristic of linear regression that training and test error deviate less than in other learning algorithms, as we will see in future sessions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1431e2a9-1504-4483-a6b4-8b36c3214caf",
   "metadata": {},
   "source": [
    "### Exercise 3: \n",
    "Now that we demonstrated one way of performing cross-validation, your task is to try out one of the other options. Becoming familiar with different options empowers you to make informed choices when having to cross-validate a model. \n",
    "\n",
    "We continue with focusing on the California Housing data and linear regression. Depending on your preferences, we propose **two flavors of the exercise**. \n",
    "\n",
    "#### Option 3.a (easier)\n",
    "If you prefer an *easier go*, your task is to implement a 10-fold cross-validation of a regression model using the function `cross_val_score()`. More specifically:\n",
    "- Examine the function's documentation and make sure you understand its key arguments.\n",
    "- Write code to call the function such that it cross-validates a linear regression model for the California Housing data set\n",
    "- Perform ten-fold cross-validation\n",
    "- Print the average performance of your model\n",
    "\n",
    "Should the above tasks have proved too easy we have a little extra task for you. Ask yourself what specific error measure your code has considered. It is not so clear, right? So your extra task could be to revise your solution such that it considers the MAE. \n",
    "\n",
    "<hr/>\n",
    "\n",
    "#### Option 3.b (harder)\n",
    "So this version is for the ambitious coders among you. It is similar to the above but involves using the function `cross_validate()`, multiple error measures, and a more sophisticated way to visualize the results. Specifically, \n",
    "- Examine the function's documentation and make sure you understand its key arguments\n",
    "- Write code to call the function such that it cross-validates a linear regression model for the California Housing data set\n",
    "- Perform ten-fold cross-validation\n",
    "- Your evaluation should comprise different error measures, namely, the MAE, the MSE, and the MAPE.\n",
    "- Visualize the performance of the regression model for each error measure using a boxplot\n",
    "\n",
    "> **Hint**: take a look into the [sklearn documentation on the scoring parameter](https://scikit-learn.org/stable/modules/model_evaluation.html#multimetric-scoring) to learn about ways of specifying error measures in a cross-validation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc229a4c-bea7-4e87-b2ed-5f2be9fa54e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution to exercise 3 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ceed3c-3d25-4055-aa49-5c3d1035189a",
   "metadata": {},
   "source": [
    "## Measuring classification performance\n",
    "We cannot finish without discussing classification performance. The evaluation of a classifier differs from a regression model because our forecasting target is a categorical and often binary variable. We focus on the latter case and return to our HMEQ data set associated with predicting good and bad credit risks.\n",
    "\n",
    "### Confusion matrix to assess discrete class predictions\n",
    "Let's start with the more intuitive case in which we assess the binary class predictions of the logistic regression model. \n",
    "\n",
    "#### Exercise 4:\n",
    "We start with an easy task to get started: \n",
    "- Split the HMEQ data set into training (70%) and test set (30%) using the holdout method\n",
    "- Train a logistic regression model on the training set\n",
    "- Compute discrete class predictions using the test set\n",
    "- Store your predictions in a variable `class_pred`\n",
    "\n",
    "You can find pretty much all the codes needed to solve this exercise in previous parts of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b65014-36dd-4c92-bf79-81a24fc6aabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for exercise 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868ed4b2-cbaf-4d54-8f7e-237529edf555",
   "metadata": {},
   "source": [
    "Well done! Having sorted this bit, let's move on with the actual assessment. We introduced the **confusion matrix** as a standard way to assess a binary classification models. Of course, `sklearn` also supports the confusion matrix and, more specifically, its visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0840ee8d-b547-4a9c-b58f-36345f16bdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "ConfusionMatrixDisplay.from_predictions(yts_hmeq,    # of course we use the test set\n",
    "                                        class_pred,  # here, we assume you solved exercise 4 and created an array of discrete class predictions\n",
    "                                        display_labels=['Good risk', 'Bad risk'])  # more readable labels for labeling the axes of our matrix\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5e17ca-60df-4cf8-abd3-2ffe7638c0fe",
   "metadata": {},
   "source": [
    "Just for the records, in case you are only interested in the entries of the confusion matrix, an easy way to get these is  as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec1f253-c74d-47a3-b55e-78715c99dc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmat = confusion_matrix(yts_hmeq, class_pred)  # Of course we use the test\n",
    "print(cmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115d7a26-8a6d-4ebb-9592-c891ed491b7f",
   "metadata": {},
   "source": [
    "### ROC analysis\n",
    "The confusion matrix suggests that our logistic regression is doing a very poor job. It consistently predicts the class *Good risk*, meaning it would give every applicant credit. Put in statistical terms, the logistic regression acts like a **naive classifier** by always predicting the majority class in the data.  \n",
    "\n",
    "Remember that the confusion matrix depicts the performance of a classifier for one specific **cut-off*. By default, `sklearn` and, more specifically, the `predict()` function, sets this cut-off to 0.5. It may be that our logistic regression is a bit more useful than we think. Specifically, it may be that the default cut-off was inappropriate and that we would see a better performance with a different cut-off. Enter **ROC-analysis**.\n",
    "\n",
    "ROC-analysis visualizes the performance of a classification model across **all possible cut-offs** and will give us a deeper understanding of whether the logistic regression is really naive or in fact able to distinguish good and bad payers to some extent. \n",
    "\n",
    "#### Exercise 5:\n",
    "Here is your task. \n",
    "- Familiarize yourself with the function `RocCurveDisplay`, which is available in the `sklearn.metrics` module.\n",
    "- Write code to obtain **probability predictions** for the test set of the HMEQ data set (you can reuse `log_reg` for this task)\n",
    "- Using the functionality of `RocCurveDisplay`, create a ROC curve.\n",
    "- Augment the curve with a diagonal line representing the random classifier. Strangely, `RocCurveDisplay` does not include it by default.\n",
    "- Write a short interpretation of the result. How well does logistic regression perform in your opinion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfa7ea0-70fe-4b2b-9dac-831af4b19409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for exercise 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094f0851-ec6d-46a4-8a3f-72cbe289d9e0",
   "metadata": {},
   "source": [
    "**Your interpretation of the ROC curve**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
